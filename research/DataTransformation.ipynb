{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83fdfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37f97c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:\\Weather_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd610169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Weather_prediction'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6abfd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba4e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Predict_weather.constants import *\n",
    "from src.Predict_weather.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84ee6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH, schema_filepath=SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path= config.data_path\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea453696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.Predict_weather import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46a62ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1827, 19)\n",
      "\n",
      "Column names:\n",
      "['date', 'temperature_2m_max', 'temperature_2m_min', 'precipitation_sum', 'rain_sum', 'precipitation_hours', 'temperature_2m_mean', 'apparent_temperature_mean', 'cloud_cover_mean', 'cloud_cover_max', 'cloud_cover_min', 'sunshine_duration', 'wind_speed_10m_max', 'wind_gusts_10m_max', 'wind_gusts_10m_mean', 'wind_speed_10m_mean', 'relative_humidity_2m_max', 'relative_humidity_2m_min', 'relative_humidity_2m_mean']\n",
      "\n",
      "First few rows:\n",
      "                        date  temperature_2m_max  temperature_2m_min  \\\n",
      "0  2020-08-14 18:30:00+00:00              27.244              22.144   \n",
      "1  2020-08-15 18:30:00+00:00              27.794              22.194   \n",
      "2  2020-08-16 18:30:00+00:00              23.994              22.544   \n",
      "3  2020-08-17 18:30:00+00:00              24.444              22.394   \n",
      "4  2020-08-18 18:30:00+00:00              27.344              22.144   \n",
      "\n",
      "   precipitation_sum   rain_sum  precipitation_hours  temperature_2m_mean  \\\n",
      "0           6.900000   6.900000                 18.0            23.887749   \n",
      "1          11.599998  11.599998                 17.0            24.239832   \n",
      "2          65.499990  65.499990                 20.0            23.108583   \n",
      "3          53.500000  53.500000                 20.0            23.062752   \n",
      "4          13.099999  13.099999                 20.0            24.085665   \n",
      "\n",
      "   apparent_temperature_mean  cloud_cover_mean  cloud_cover_max  \\\n",
      "0                  26.387281         99.708336            100.0   \n",
      "1                  27.173525         99.666664            100.0   \n",
      "2                  26.037016         99.958336            100.0   \n",
      "3                  25.709036        100.000000            100.0   \n",
      "4                  26.299780         89.208336            100.0   \n",
      "\n",
      "   cloud_cover_min  sunshine_duration  wind_speed_10m_max  wind_gusts_10m_max  \\\n",
      "0             97.0         11183.3430           23.210928               45.00   \n",
      "1             98.0          3441.2383           22.288042               42.12   \n",
      "2             99.0             0.0000           18.671474               34.92   \n",
      "3            100.0             0.0000           18.806337               36.36   \n",
      "4             63.0         27248.9020           24.400460               46.80   \n",
      "\n",
      "   wind_gusts_10m_mean  wind_speed_10m_mean  relative_humidity_2m_max  \\\n",
      "0            31.905000            15.910668                 94.962425   \n",
      "1            29.174997            14.512328                 95.538380   \n",
      "2            28.095001            14.444237                 96.131600   \n",
      "3            30.494997            15.825063                 96.413826   \n",
      "4            35.459995            18.013298                 94.964294   \n",
      "\n",
      "   relative_humidity_2m_min  relative_humidity_2m_mean  \n",
      "0                 72.612100                  88.235960  \n",
      "1                 73.150450                  88.800720  \n",
      "2                 92.172400                  94.593506  \n",
      "3                 90.527990                  94.042330  \n",
      "4                 72.408295                  87.796760  \n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the actual structure of the weather data\n",
    "data_path = \"artifacts/data_ingestion/weather.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(list(data.columns))\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af132096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    \n",
    "    def transform_data(self):\n",
    "        \n",
    "        data = pd.read_csv(self.config.data_path)\n",
    "        \n",
    "        # Ensure the 'date' column exists before processing\n",
    "        if 'date' not in data.columns:\n",
    "            logger.error(f\"Column 'date' not found in the dataset. Available columns: {list(data.columns)}\")\n",
    "            raise KeyError(\"Column 'date' not found in the dataset.\")\n",
    "        \n",
    "        # Extract day, year, and month from the 'date' column\n",
    "        data['day'] = pd.to_datetime(data['date'], errors='coerce').dt.day\n",
    "        data['year'] = pd.to_datetime(data['date'], errors='coerce').dt.year\n",
    "        data['month'] = pd.to_datetime(data['date'], errors='coerce').dt.month\n",
    "        \n",
    "        # Remove the original date column after extracting temporal features\n",
    "        data = data.drop('date', axis=1)\n",
    "        \n",
    "        train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train.to_csv(os.path.join(self.config.root_dir, \"train.csv\"), index=False)\n",
    "        test.to_csv(os.path.join(self.config.root_dir, \"test.csv\"), index=False)\n",
    "        \n",
    "        logger.info(\"Splitted data into training and test sets\")\n",
    "        logger.info(\"Removed original date column after extracting temporal features\")\n",
    "        logger.info(f\"Train shape: {train.shape}\")\n",
    "        logger.info(f\"Test shape: {test.shape}\")\n",
    "        \n",
    "        print(f\"Train shape: {train.shape}\")            \n",
    "        print(f\"Test shape: {test.shape}\")\n",
    "        print(\"Date column removed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d9b5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-02 21:47:29,197: INFO: common: yaml file: config\\config.yml loaded successfully]\n",
      "[2025-09-02 21:47:29,200: INFO: common: yaml file: params.yml loaded successfully]\n",
      "[2025-09-02 21:47:29,204: INFO: common: yaml file: schema.yml loaded successfully]\n",
      "[2025-09-02 21:47:29,200: INFO: common: yaml file: params.yml loaded successfully]\n",
      "[2025-09-02 21:47:29,204: INFO: common: yaml file: schema.yml loaded successfully]\n",
      "[2025-09-02 21:47:29,206: INFO: common: created directory at: artifacts]\n",
      "[2025-09-02 21:47:29,208: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-09-02 21:47:29,206: INFO: common: created directory at: artifacts]\n",
      "[2025-09-02 21:47:29,208: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-09-02 21:47:29,249: INFO: 2267750694: Splitted data into training and test sets]\n",
      "[2025-09-02 21:47:29,250: INFO: 2267750694: Removed original date column after extracting temporal features]\n",
      "[2025-09-02 21:47:29,251: INFO: 2267750694: Train shape: (1461, 21)]\n",
      "[2025-09-02 21:47:29,252: INFO: 2267750694: Test shape: (366, 21)]\n",
      "Train shape: (1461, 21)\n",
      "Test shape: (366, 21)\n",
      "Date column removed successfully!\n",
      "[2025-09-02 21:47:29,249: INFO: 2267750694: Splitted data into training and test sets]\n",
      "[2025-09-02 21:47:29,250: INFO: 2267750694: Removed original date column after extracting temporal features]\n",
      "[2025-09-02 21:47:29,251: INFO: 2267750694: Train shape: (1461, 21)]\n",
      "[2025-09-02 21:47:29,252: INFO: 2267750694: Test shape: (366, 21)]\n",
      "Train shape: (1461, 21)\n",
      "Test shape: (366, 21)\n",
      "Date column removed successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.transform_data()  # Fixed method name from transfomrm_data to transform_data\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01232b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
